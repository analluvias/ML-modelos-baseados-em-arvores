
# üßæ Modelos Baseados em √Årvores (Classifica√ß√£o e Regress√£o)

## Sobre o Projeto

Este notebook demonstra o uso de **Modelos de Aprendizado de M√°quina baseados em √Årvores de Decis√£o**, aplicados a dois problemas distintos:

1. **Classifica√ß√£o** ‚Äì Diagn√≥stico de c√¢ncer de mama (dataset *Breast Cancer Wisconsin*).  
2. **Regress√£o** ‚Äì Predi√ß√£o do consumo de combust√≠vel (*milhas por gal√£o*) com base em caracter√≠sticas de autom√≥veis (*dataset Auto MPG*).

O objetivo √© compreender:
- Como funcionam as **√°rvores de decis√£o** para **classifica√ß√£o** e **regress√£o**.  
- Como ajustar **hiperpar√¢metros** como profundidade e crit√©rio de divis√£o.  
- Como avaliar **acur√°cia** e **erro m√©dio quadr√°tico (RMSE)**.  
- Como diagnosticar **vi√©s e vari√¢ncia**.  
- Como comparar o modelo com um **baseline** simples.

---

## Conceitos Envolvidos

### √Årvore de Decis√£o
Um modelo preditivo que divide o espa√ßo de decis√£o em regi√µes menores, com base em perguntas (condi√ß√µes) sobre as vari√°veis.  
√â f√°cil de interpretar e serve tanto para **classifica√ß√£o** quanto **regress√£o**.

### Crit√©rios de Divis√£o
- **Gini**: mede a impureza de um n√≥ (padr√£o para classifica√ß√£o).  
- **Entropia**: mede a quantidade de informa√ß√£o necess√°ria para classificar corretamente as amostras.

### üîπ Vi√©s e Vari√¢ncia
- **Vi√©s (bias)**: tend√™ncia de simplificar demais (subajuste).  
- **Vari√¢ncia**: sensibilidade exagerada aos dados de treino (superajuste).  
O equil√≠brio entre ambos √© essencial para um bom modelo.

---

## Tecnologias Utilizadas

- **Python 3.10+**
- **Google Colab**
- **Bibliotecas:**
  - `pandas`
  - `numpy`
  - `scikit-learn`
  - `matplotlib`

---

## Datasets

1. **Breast Cancer Wisconsin (WBC)**  
   üìé [Link](https://assets.datacamp.com/production/repositories/1796/datasets/0eb6987cb9633e4d6aa6cfd11e00993d2387caa4/wbc.csv)

   Usado para **classifica√ß√£o bin√°ria** (diagn√≥stico de c√¢ncer).  
   **Target:** `diagnosis`

2. **Auto MPG**  
   üìé [Link](https://assets.datacamp.com/production/repositories/1796/datasets/3781d588cf7b04b1e376c7e9dda489b3e6c7465b/auto.csv)

   Usado para **regress√£o** (predi√ß√£o de `mpg` ‚Äî milhas por gal√£o).  
   A coluna `origin` foi codificada via *One-Hot Encoding*.

---

## Etapas do Projeto

### 1. √Årvore de Decis√£o para Classifica√ß√£o
- Importa√ß√£o do dataset *WBC*.
- Divis√£o em treino e teste.
- Treinamento com `DecisionTreeClassifier`.
- Compara√ß√£o entre crit√©rios `gini` e `entropy`.
- Avalia√ß√£o da acur√°cia (~93%).

### 2. √Årvore de Decis√£o para Regress√£o
- Importa√ß√£o do dataset *Auto MPG*.
- Codifica√ß√£o das vari√°veis categ√≥ricas (`origin`).
- Treinamento com `DecisionTreeRegressor`.
- C√°lculo de m√©tricas de erro (RMSE) para:
  - Treino (`RMSE_train`)
  - Teste (`RMSE_test`)
  - Valida√ß√£o cruzada (`RMSE_CV`)
  - Baseline (modelo que prev√™ sempre a m√©dia)

### 3. An√°lise de Vi√©s e Vari√¢ncia
- Compara√ß√£o entre erros de treino, teste e baseline.
- Interpreta√ß√£o dos resultados em rela√ß√£o a *overfitting* e *underfitting*.

### 4. Visualiza√ß√£o
- Gr√°fico de barras mostrando `RMSE_baseline`, `RMSE_train` e `RMSE_test`.

---

## Resultados Obtidos

| M√©trica | Valor (aprox.) | Interpreta√ß√£o |
|----------|----------------|---------------|
| **RMSE_train** | 3.85 | Erro m√©dio do modelo no treino |
| **RMSE_test** | 4.82 | Erro m√©dio do modelo no teste |
| **RMSE_baseline** | 8.03 | Erro se o modelo previsse apenas a m√©dia |

**Conclus√µes:**
- O modelo reduziu o erro em quase **40%** em rela√ß√£o ao baseline.  
- Pequena diferen√ßa entre treino e teste ‚Üí **modelo bem equilibrado**.  
- O modelo **aprendeu padr√µes reais** sem superajustar.

---

## Interpreta√ß√£o Final

O modelo de regress√£o por √°rvore de decis√£o:
- Desempenha **significativamente melhor** do que o baseline.
- Mostra **boa generaliza√ß√£o** (sem overfitting).
- Est√° **adequadamente configurado** com `max_depth=8` e `min_samples_leaf=0.13`.

**Conclus√£o geral:**  
Os modelos baseados em √°rvore s√£o eficazes tanto para classifica√ß√£o quanto para regress√£o, oferecendo bom desempenho e interpretabilidade, mesmo com configura√ß√µes simples.

---

## Visualiza√ß√£o de RMSE

```python
import matplotlib.pyplot as plt

rmse_values = [rmse_baseline, RMSE_train, RMSE_test]
labels = ['Baseline', 'Treino', 'Teste']

plt.bar(labels, rmse_values, color=['gray', 'skyblue', 'orange'])
plt.title('Compara√ß√£o de RMSE')
plt.ylabel('RMSE (quanto menor, melhor)')
plt.show()
```

---

## Autoria

Projeto desenvolvido por **Ana Meira**  
Assunto: *Aprendizado de M√°quina / Modelos Baseados em √Årvores*  
Ferramenta: *Google Colab*
